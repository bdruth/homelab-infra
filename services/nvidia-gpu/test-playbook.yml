---
# Test playbook for NVIDIA GPU configuration

- name: Define nvidia-gpu group dynamically
  hosts: all
  gather_facts: false
  tasks:
    - name: Add host to nvidia_gpu_hosts group if it has the role
      ansible.builtin.group_by:
        key: "nvidia_gpu_hosts"
      when: "'nvidia-gpu' in hostvars[inventory_hostname].get('host_roles', [])"
      changed_when: false

- name: Validate NVIDIA GPU configuration
  hosts: nvidia_gpu_hosts
  become: true
  gather_facts: true
  roles:
    - nvidia-gpu
  tasks:
    - name: Check NVIDIA driver is installed
      ansible.builtin.command: nvidia-smi
      register: nvidia_smi_result
      changed_when: false
      ignore_errors: true
      when: nvidia_install_gpu_drivers is defined and nvidia_install_gpu_drivers | bool

    - name: Display NVIDIA driver status
      ansible.builtin.debug:
        msg: "NVIDIA driver status: {{ 'OK' if nvidia_smi_result.rc is defined and nvidia_smi_result.rc == 0 else 'Not properly installed or not enabled' }}"
      when: nvidia_install_gpu_drivers is defined and nvidia_install_gpu_drivers | bool

    - name: Check CUDA toolkit is installed
      ansible.builtin.command: nvcc --version
      register: nvcc_result
      changed_when: false
      ignore_errors: true
      when: nvidia_install_cuda_toolkit is defined and nvidia_install_cuda_toolkit | bool

    - name: Display CUDA toolkit status
      ansible.builtin.debug:
        msg: >-
          CUDA toolkit status: {{ 'OK' if nvcc_result.rc is defined and nvcc_result.rc == 0
          else 'Not properly installed or not enabled' }}
      when: nvidia_install_cuda_toolkit is defined and nvidia_install_cuda_toolkit | bool

    - name: Check if docker-compose is installed
      ansible.builtin.command: docker-compose --version
      register: docker_compose_result
      changed_when: false
      ignore_errors: true
      when: install_docker_compose is defined and install_docker_compose | bool

    - name: Display docker-compose status
      ansible.builtin.debug:
        msg: >-
          docker-compose status: {{ 'OK' if docker_compose_result.rc is defined and docker_compose_result.rc == 0
          else 'Not properly installed or not enabled' }}
      when: install_docker_compose is defined and install_docker_compose | bool

    - name: Check if btop is installed
      ansible.builtin.command: btop --version
      register: btop_result
      changed_when: false
      ignore_errors: true
      when: install_btop is defined and install_btop | bool

    - name: Display btop status
      ansible.builtin.debug:
        msg: "btop status: {{ 'OK' if btop_result.rc is defined and btop_result.rc == 0 else 'Not properly installed or not enabled' }}"
      when: install_btop is defined and install_btop | bool

    - name: Check if Ollama is installed
      ansible.builtin.command: ollama --version
      register: ollama_result
      changed_when: false
      ignore_errors: true
      when: install_ollama is defined and install_ollama | bool

    - name: Display Ollama status
      ansible.builtin.debug:
        msg: "Ollama status: {{ 'OK' if ollama_result.rc is defined and ollama_result.rc == 0 else 'Not properly installed or not enabled' }}"
      when: install_ollama is defined and install_ollama | bool

    - name: Check if uv is installed with bash
      ansible.builtin.command: bash -i -c "uv --version"
      register: uv_result
      changed_when: false
      ignore_errors: true
      when: install_uv is defined and install_uv | bool

    - name: Display uv status
      ansible.builtin.debug:
        msg: "uv status: {{ 'OK' if uv_result.rc is defined and uv_result.rc == 0 else 'Not properly installed or not enabled' }}"
      when: install_uv is defined and install_uv | bool

    - name: Wait for n8n container to start
      ansible.builtin.shell: docker ps | grep n8n
      register: n8n_result
      changed_when: false
      ignore_errors: true
      retries: 15
      delay: 4
      until: n8n_result.rc == 0
      when: install_n8n is defined and install_n8n | bool

    - name: Display n8n status
      ansible.builtin.debug:
        msg: "n8n status: {{ 'OK' if n8n_result.rc is defined and n8n_result.rc == 0 else 'Not properly installed or not running' }}"
      when: install_n8n is defined and install_n8n | bool

    - name: Wait for Whisper ASR container to start
      ansible.builtin.shell: docker ps | grep whisper
      register: whisper_asr_result
      changed_when: false
      ignore_errors: true
      retries: 15
      delay: 4
      until: whisper_asr_result.rc == 0
      when: install_whisper_asr is defined and install_whisper_asr | bool

    - name: Display Whisper ASR status
      ansible.builtin.debug:
        msg: "Whisper ASR status: {{ 'OK' if whisper_asr_result.rc is defined and whisper_asr_result.rc == 0 else 'Not properly installed or not running' }}"
      when: install_whisper_asr is defined and install_whisper_asr | bool

    - name: Wait for Whisper ASR HTTP service to become available
      ansible.builtin.uri:
        url: "http://localhost:{{ whisper_asr_port }}/docs"
        method: GET
        status_code: 200
        timeout: 120
      register: whisper_http_check
      retries: 12
      delay: 5
      until: whisper_http_check.status == 200
      ignore_errors: true
      when:
        - install_whisper_asr is defined and install_whisper_asr | bool
        - whisper_asr_result.rc is defined and whisper_asr_result.rc == 0

    - name: Check if CUDA is available inside Whisper ASR container
      ansible.builtin.shell: >
        docker exec whisper-asr /bin/bash -c "source .venv/bin/activate && python3 -c 'import torch; print(torch.cuda.is_available())'"
      register: whisper_cuda_result
      changed_when: false
      ignore_errors: true
      when:
        - install_whisper_asr is defined and install_whisper_asr | bool
        - nvidia_install_gpu_drivers is defined and nvidia_install_gpu_drivers | bool
        - whisper_asr_result.rc is defined and whisper_asr_result.rc == 0
        - whisper_http_check.status is defined and whisper_http_check.status == 200

    - name: Display Whisper ASR CUDA access status
      ansible.builtin.debug:
        msg: "Whisper ASR CUDA access: {{ 'OK - GPU access confirmed' if whisper_cuda_result.stdout_lines[0] == 'True' else 'Not connected to GPU' }}"
      when:
        - install_whisper_asr is defined and install_whisper_asr | bool
        - nvidia_install_gpu_drivers is defined and nvidia_install_gpu_drivers | bool
        - whisper_asr_result.rc is defined and whisper_asr_result.rc == 0
        - whisper_http_check.status is defined and whisper_http_check.status == 200

    - name: Wait for Open WebUI container to start
      ansible.builtin.shell: docker ps | grep open-webui
      register: open_webui_result
      changed_when: false
      ignore_errors: true
      retries: 15
      delay: 4
      until: open_webui_result.rc == 0
      when: install_open_webui is defined and install_open_webui | bool

    - name: Display Open WebUI status
      ansible.builtin.debug:
        msg: "Open WebUI status: {{ 'OK' if open_webui_result.rc is defined and open_webui_result.rc == 0 else 'Not properly installed or not running' }}"
      when: install_open_webui is defined and install_open_webui | bool

    - name: Wait for Open WebUI HTTP service to become available
      ansible.builtin.uri:
        url: "http://localhost:{{ open_webui_port }}"
        method: GET
        status_code: 200
        timeout: 120
      register: open_webui_http_check
      retries: 12
      delay: 5
      until: open_webui_http_check.status == 200
      ignore_errors: true
      when:
        - install_open_webui is defined and install_open_webui | bool
        - open_webui_result.rc is defined and open_webui_result.rc == 0

    - name: Check if CUDA is available inside Open WebUI container
      ansible.builtin.shell: >
        docker exec open-webui /bin/bash -c "python3 -c 'import torch; print(torch.cuda.is_available())'"
      register: open_webui_cuda_result
      changed_when: false
      ignore_errors: true
      when:
        - install_open_webui is defined and install_open_webui | bool
        - nvidia_install_gpu_drivers is defined and nvidia_install_gpu_drivers | bool
        - open_webui_result.rc is defined and open_webui_result.rc == 0
        - open_webui_http_check.status is defined and open_webui_http_check.status == 200

    - name: Display Open WebUI CUDA access status
      ansible.builtin.debug:
        msg: "Open WebUI CUDA access: {{ 'OK - GPU access confirmed' if open_webui_cuda_result.stdout_lines[0] == 'True' else 'Not connected to GPU' }}"
      when:
        - install_open_webui is defined and install_open_webui | bool
        - nvidia_install_gpu_drivers is defined and nvidia_install_gpu_drivers | bool
        - open_webui_result.rc is defined and open_webui_result.rc == 0
        - open_webui_http_check.status is defined and open_webui_http_check.status == 200

    - name: Check Open WebUI Web RAG configuration
      ansible.builtin.shell: >
        docker inspect open-webui | grep -E "ENABLE_RAG_WEB_SEARCH|ENABLE_SEARCH_QUERY_GENERATION|RAG_WEB_SEARCH_ENGINE|RAG_WEB_LOADER_ENGINE"
      register: open_webui_rag_config_result
      changed_when: false
      ignore_errors: true
      when:
        - install_open_webui is defined and install_open_webui | bool
        - open_webui_result.rc is defined and open_webui_result.rc == 0
        - open_webui_enable_rag_web_search is defined and open_webui_enable_rag_web_search | bool

    - name: Display Open WebUI Web RAG configuration status
      ansible.builtin.debug:
        msg: "Open WebUI Web RAG configuration: {{
          'OK - Configured correctly' if open_webui_rag_config_result.rc is defined and open_webui_rag_config_result.rc == 0
          else 'Not properly configured' }}"
      when:
        - install_open_webui is defined and install_open_webui | bool
        - open_webui_result.rc is defined and open_webui_result.rc == 0
        - open_webui_enable_rag_web_search is defined and open_webui_enable_rag_web_search | bool

    - name: Check Open WebUI Image Generation configuration
      ansible.builtin.shell: >-
        docker inspect open-webui |
        grep -E "COMFYUI_BASE_URL|ENABLE_IMAGE_GENERATION"
      register: open_webui_image_gen_result
      changed_when: false
      ignore_errors: true
      when:
        - install_open_webui is defined and install_open_webui | bool
        - install_comfyui is defined and install_comfyui | bool
        - open_webui_result.rc is defined and open_webui_result.rc == 0
        - open_webui_enable_image_generation is defined and open_webui_enable_image_generation | bool

    - name: Display Open WebUI Image Generation status
      ansible.builtin.debug:
        msg: "Open WebUI Image Generation: {{
          'OK - Configured correctly' if open_webui_image_gen_result.rc is defined and open_webui_image_gen_result.rc == 0
          else 'Not properly configured' }}"
      when:
        - install_open_webui is defined and install_open_webui | bool
        - install_comfyui is defined and install_comfyui | bool
        - open_webui_result.rc is defined and open_webui_result.rc == 0
        - open_webui_enable_image_generation is defined and open_webui_enable_image_generation | bool

    - name: Check GPT Researcher service status
      ansible.builtin.systemd:
        name: gpt-researcher
      register: gpt_researcher_service_status
      ignore_errors: true
      when: install_gpt_researcher is defined and install_gpt_researcher | bool

    - name: Display GPT Researcher service status
      ansible.builtin.debug:
        msg: >-
          GPT Researcher service status: {{
            'OK - Active' if gpt_researcher_service_status.status.ActiveState is defined
            and gpt_researcher_service_status.status.ActiveState == 'active'
            else 'Failed - Not active'
          }}
      when: install_gpt_researcher is defined and install_gpt_researcher | bool

    - name: Check GPT Researcher service journal for errors (last 20 lines)
      ansible.builtin.command: journalctl -u gpt-researcher -n 20 --no-pager
      register: gpt_researcher_journal
      changed_when: false
      ignore_errors: true
      when:
        - install_gpt_researcher is defined and install_gpt_researcher | bool
        - gpt_researcher_service_status.status.ActiveState is defined and gpt_researcher_service_status.status.ActiveState != 'active'

    - name: Display GPT Researcher journal errors
      ansible.builtin.debug:
        msg: "GPT Researcher service errors found in journal. See output for details."
        verbosity: 0
      when:
        - install_gpt_researcher is defined and install_gpt_researcher | bool
        - gpt_researcher_service_status.status.ActiveState is defined and gpt_researcher_service_status.status.ActiveState != 'active'
        - gpt_researcher_journal is defined

    - name: Display GPT Researcher journal output
      ansible.builtin.debug:
        var: gpt_researcher_journal.stdout_lines
        verbosity: 0
      when:
        - install_gpt_researcher is defined and install_gpt_researcher | bool
        - gpt_researcher_service_status.status.ActiveState is defined and gpt_researcher_service_status.status.ActiveState != 'active'
        - gpt_researcher_journal is defined

    - name: Wait for GPT Researcher container to start
      ansible.builtin.shell: docker ps | grep gpt-researcher
      register: gpt_researcher_result
      changed_when: false
      ignore_errors: true
      retries: 15
      delay: 4
      until: gpt_researcher_result.rc == 0
      when:
        - install_gpt_researcher is defined and install_gpt_researcher | bool
        - gpt_researcher_service_status.status.ActiveState is defined and gpt_researcher_service_status.status.ActiveState == 'active'

    - name: Display GPT Researcher container status
      ansible.builtin.debug:
        msg: "GPT Researcher container status: {{ 'OK' if gpt_researcher_result.rc is defined and gpt_researcher_result.rc == 0 else 'Not running' }}"
      when:
        - install_gpt_researcher is defined and install_gpt_researcher | bool
        - gpt_researcher_service_status.status.ActiveState is defined and gpt_researcher_service_status.status.ActiveState == 'active'

    - name: Wait for GPT Researcher HTTP service to become available
      ansible.builtin.uri:
        url: "http://localhost:{{ gpt_researcher_port }}"
        method: GET
        status_code: 200
        timeout: 120
      register: gpt_researcher_http_check
      retries: 12
      delay: 5
      until: gpt_researcher_http_check.status == 200
      ignore_errors: true
      when:
        - install_gpt_researcher is defined and install_gpt_researcher | bool
        - gpt_researcher_service_status.status.ActiveState is defined
        - gpt_researcher_service_status.status.ActiveState == 'active'
        - gpt_researcher_result.rc is defined and gpt_researcher_result.rc == 0

    - name: Check if ComfyUI installation exists
      ansible.builtin.stat:
        path: "{{ comfyui_install_dir }}/main.py"
      register: comfyui_install_check
      when: install_comfyui is defined and install_comfyui | bool

    - name: Display ComfyUI installation status
      ansible.builtin.debug:
        msg: "ComfyUI installation: {{ 'OK - Installed' if comfyui_install_check.stat.exists else 'Not properly installed' }}"
      when: install_comfyui is defined and install_comfyui | bool

    - name: Check if Python virtual environment exists
      ansible.builtin.stat:
        path: "{{ comfyui_venv_path }}/bin/python"
      register: comfyui_venv_check
      when:
        - install_comfyui is defined and install_comfyui | bool
        - comfyui_install_check.stat.exists is defined and comfyui_install_check.stat.exists

    - name: Display Python venv status
      ansible.builtin.debug:
        msg: "ComfyUI Python venv: {{ 'OK - Environment setup' if comfyui_venv_check.stat.exists else 'Virtual environment missing' }}"
      when:
        - install_comfyui is defined and install_comfyui | bool
        - comfyui_install_check.stat.exists is defined and comfyui_install_check.stat.exists

    - name: Check if CUDA is available for ComfyUI
      ansible.builtin.command:
        cmd: "{{ comfyui_venv_path }}/bin/python -c 'import torch; print(torch.cuda.is_available())'"
      register: comfyui_cuda_result
      changed_when: false
      ignore_errors: true
      become: true
      become_user: "{{ comfyui_user }}"
      when:
        - install_comfyui is defined and install_comfyui | bool
        - nvidia_install_gpu_drivers is defined and nvidia_install_gpu_drivers | bool
        - comfyui_install_check.stat.exists is defined and comfyui_install_check.stat.exists
        - comfyui_venv_check.stat.exists is defined and comfyui_venv_check.stat.exists

    - name: Display ComfyUI CUDA access status
      ansible.builtin.debug:
        msg: "ComfyUI CUDA access: {{ 'OK - GPU access confirmed' if comfyui_cuda_result.stdout_lines[0] == 'True' else 'Not connected to GPU' }}"
      when:
        - install_comfyui is defined and install_comfyui | bool
        - nvidia_install_gpu_drivers is defined and nvidia_install_gpu_drivers | bool
        - comfyui_install_check.stat.exists is defined and comfyui_install_check.stat.exists
        - comfyui_venv_check.stat.exists is defined and comfyui_venv_check.stat.exists
        - comfyui_cuda_result is defined

    - name: Check if ComfyUI service is running
      ansible.builtin.systemd:
        name: comfyui
        state: started
      register: comfyui_service_status
      ignore_errors: true
      when:
        - install_comfyui is defined and install_comfyui | bool
        - comfyui_install_check.stat.exists is defined and comfyui_install_check.stat.exists
        - comfyui_venv_check.stat.exists is defined and comfyui_venv_check.stat.exists

    - name: Get ComfyUI service configuration
      ansible.builtin.command: cat /etc/systemd/system/comfyui.service
      register: comfyui_service_content
      changed_when: false
      ignore_errors: true
      when:
        - install_comfyui is defined and install_comfyui | bool
        - comfyui_install_check.stat.exists is defined and comfyui_install_check.stat.exists
        - comfyui_service_status.status.ActiveState is defined and comfyui_service_status.status.ActiveState == 'active'

    - name: Check for lowvram and cpu-vae flags in service file
      ansible.builtin.set_fact:
        lowvram_enabled: "{{ '--lowvram' in comfyui_service_content.stdout | default('') }}"
        cpu_vae_enabled: "{{ '--cpu-vae' in comfyui_service_content.stdout | default('') }}"
      when:
        - install_comfyui is defined and install_comfyui | bool
        - comfyui_install_check.stat.exists is defined and comfyui_install_check.stat.exists
        - comfyui_service_status.status.ActiveState is defined and comfyui_service_status.status.ActiveState == 'active'
        - comfyui_service_content is defined

    - name: Display ComfyUI service status
      ansible.builtin.debug:
        msg: >
          ComfyUI service:
          - Status: {{ 'OK - Service running' if comfyui_service_status.status.ActiveState == 'active' else 'Service not running' }}
          - Low VRAM mode: {{ 'Enabled' if lowvram_enabled | default(false) else 'Disabled' }}
          - CPU VAE mode: {{ 'Enabled' if cpu_vae_enabled | default(false) else 'Disabled' }}
      when:
        - install_comfyui is defined and install_comfyui | bool
        - comfyui_install_check.stat.exists is defined and comfyui_install_check.stat.exists
        - comfyui_venv_check.stat.exists is defined and comfyui_venv_check.stat.exists

    # Check shared models base directory
    - name: Check if shared models directory exists
      ansible.builtin.stat:
        path: "/opt/shared-models"
      register: shared_models_dir
      when:
        - install_shared_models is defined and install_shared_models | bool

    # Check ComfyUI model links
    - name: Check if FLUX.1 model is linked to ComfyUI
      ansible.builtin.stat:
        path: "{{ comfyui_install_dir }}/models/checkpoints/{{ comfyui_flux1_model_filename }}"
      register: flux1_model_check
      when:
        - install_comfyui is defined and install_comfyui | bool
        - install_shared_models is defined and install_shared_models | bool
        - comfyui_install_flux1 is defined and comfyui_install_flux1 | bool
        - comfyui_install_check.stat.exists is defined and comfyui_install_check.stat.exists

    - name: Check if FLUX.1 VAE model is linked to ComfyUI
      ansible.builtin.stat:
        path: "{{ comfyui_install_dir }}/models/vae/ae.safetensors"
      register: flux1_vae_check
      when:
        - install_comfyui is defined and install_comfyui | bool
        - install_shared_models is defined and install_shared_models | bool
        - comfyui_install_flux1 is defined and comfyui_install_flux1 | bool
        - comfyui_install_check.stat.exists is defined and comfyui_install_check.stat.exists

    - name: Check if FLUX.1 CLIP model is linked to ComfyUI
      ansible.builtin.stat:
        path: "{{ comfyui_install_dir }}/models/clip/clip_l.safetensors"
      register: flux1_clip_check
      when:
        - install_comfyui is defined and install_comfyui | bool
        - install_shared_models is defined and install_shared_models | bool
        - comfyui_install_flux1 is defined and comfyui_install_flux1 | bool
        - comfyui_install_check.stat.exists is defined and comfyui_install_check.stat.exists

    - name: Check if FLUX.1 T5XXL model is linked to ComfyUI
      ansible.builtin.stat:
        path: "{{ comfyui_install_dir }}/models/clip/{{ comfyui_t5xxl_filename }}"
      register: flux1_t5xxl_check
      when:
        - install_comfyui is defined and install_comfyui | bool
        - install_shared_models is defined and install_shared_models | bool
        - comfyui_install_flux1 is defined and comfyui_install_flux1 | bool
        - comfyui_install_check.stat.exists is defined and comfyui_install_check.stat.exists

    - name: Display FLUX.1 models status in ComfyUI
      ansible.builtin.debug:
        msg: >
          FLUX.1 models in ComfyUI:
          - Main model ({{ comfyui_flux1_model_filename }}): {{ 'OK - Linked' if flux1_model_check.stat.exists else 'Not found' }}
          - VAE model: {{ 'OK - Linked' if flux1_vae_check.stat.exists else 'Not found' }}
          - CLIP model: {{ 'OK - Linked' if flux1_clip_check.stat.exists else 'Not found' }}
          - T5XXL model: {{ 'OK - Linked' if flux1_t5xxl_check.stat.exists else 'Not found' }}
      when:
        - install_comfyui is defined and install_comfyui | bool
        - install_shared_models is defined and install_shared_models | bool
        - comfyui_install_flux1 is defined and comfyui_install_flux1 | bool
        - comfyui_install_check.stat.exists is defined and comfyui_install_check.stat.exists

    - name: Check if SD v1.5 model is linked to ComfyUI checkpoints
      ansible.builtin.stat:
        path: "{{ comfyui_install_dir }}/models/checkpoints/{{ comfyui_sd_v15_filename }}"
      register: sd_v15_check
      when:
        - install_comfyui is defined and install_comfyui | bool
        - install_shared_models is defined and install_shared_models | bool
        - comfyui_install_sd_v15 is defined and comfyui_install_sd_v15 | bool
        - comfyui_install_check.stat.exists is defined and comfyui_install_check.stat.exists

    - name: Check if SD v1.5 model is linked to ComfyUI unet directory
      ansible.builtin.stat:
        path: "{{ comfyui_install_dir }}/models/unet/{{ comfyui_sd_v15_filename }}"
      register: sd_v15_unet_check
      when:
        - install_comfyui is defined and install_comfyui | bool
        - install_shared_models is defined and install_shared_models | bool
        - comfyui_install_sd_v15 is defined and comfyui_install_sd_v15 | bool
        - comfyui_install_check.stat.exists is defined and comfyui_install_check.stat.exists

    - name: Display SD v1.5 model status in ComfyUI
      ansible.builtin.debug:
        msg: >
          Stable Diffusion v1.5 model in ComfyUI:
          - Checkpoints directory: {{ 'OK - Linked' if sd_v15_check.stat.exists else 'Not found' }}
          - Unet directory: {{ 'OK - Linked' if sd_v15_unet_check.stat.exists else 'Not found' }}
      when:
        - install_comfyui is defined and install_comfyui | bool
        - install_shared_models is defined and install_shared_models | bool
        - comfyui_install_sd_v15 is defined and comfyui_install_sd_v15 | bool
        - comfyui_install_check.stat.exists is defined and comfyui_install_check.stat.exists

    # Check Open WebUI model links
    - name: Check if FLUX.1 model is linked to Open WebUI diffusion models
      ansible.builtin.stat:
        path: "{{ open_webui_install_dir }}/data/models/diffusion_models/{{ comfyui_flux1_model_filename }}"
      register: openwebui_flux1_diffusion_check
      when:
        - install_open_webui is defined and install_open_webui | bool
        - install_shared_models is defined and install_shared_models | bool
        - comfyui_install_flux1 is defined and comfyui_install_flux1 | bool

    - name: Check if FLUX.1 model is linked to Open WebUI checkpoints
      ansible.builtin.stat:
        path: "{{ open_webui_install_dir }}/data/models/checkpoints/{{ comfyui_flux1_model_filename }}"
      register: openwebui_flux1_checkpoints_check
      when:
        - install_open_webui is defined and install_open_webui | bool
        - install_shared_models is defined and install_shared_models | bool
        - comfyui_install_flux1 is defined and comfyui_install_flux1 | bool

    - name: Display FLUX.1 model status in Open WebUI
      ansible.builtin.debug:
        msg: >
          FLUX.1 model in Open WebUI:
          - Diffusion models directory: {{ 'OK - Linked' if openwebui_flux1_diffusion_check.stat.exists else 'Not found' }}
          - Checkpoints directory: {{ 'OK - Linked' if openwebui_flux1_checkpoints_check.stat.exists else 'Not found' }}
      when:
        - install_open_webui is defined and install_open_webui | bool
        - install_shared_models is defined and install_shared_models | bool
        - comfyui_install_flux1 is defined and comfyui_install_flux1 | bool

    - name: Check if SD v1.5 model is linked to Open WebUI diffusion models
      ansible.builtin.stat:
        path: "{{ open_webui_install_dir }}/data/models/diffusion_models/{{ comfyui_sd_v15_filename }}"
      register: openwebui_sd_v15_diffusion_check
      when:
        - install_open_webui is defined and install_open_webui | bool
        - install_shared_models is defined and install_shared_models | bool
        - comfyui_install_sd_v15 is defined and comfyui_install_sd_v15 | bool

    - name: Check if SD v1.5 model is linked to Open WebUI checkpoints
      ansible.builtin.stat:
        path: "{{ open_webui_install_dir }}/data/models/checkpoints/{{ comfyui_sd_v15_filename }}"
      register: openwebui_sd_v15_checkpoints_check
      when:
        - install_open_webui is defined and install_open_webui | bool
        - install_shared_models is defined and install_shared_models | bool
        - comfyui_install_sd_v15 is defined and comfyui_install_sd_v15 | bool

    - name: Display SD v1.5 model status in Open WebUI
      ansible.builtin.debug:
        msg: >
          Stable Diffusion v1.5 model in Open WebUI:
          - Diffusion models directory: {{ 'OK - Linked' if openwebui_sd_v15_diffusion_check.stat.exists else 'Not found' }}
          - Checkpoints directory: {{ 'OK - Linked' if openwebui_sd_v15_checkpoints_check.stat.exists else 'Not found' }}
      when:
        - install_open_webui is defined and install_open_webui | bool
        - install_shared_models is defined and install_shared_models | bool
        - comfyui_install_sd_v15 is defined and comfyui_install_sd_v15 | bool

    - name: Wait for ComfyUI HTTP service to become available
      ansible.builtin.uri:
        url: "http://{{ ansible_default_ipv4.address }}:{{ comfyui_port }}"
        method: GET
        status_code: 200
        timeout: 120
      register: comfyui_http_check
      retries: 12
      delay: 5
      until: comfyui_http_check.status == 200
      ignore_errors: true
      when:
        - install_comfyui is defined and install_comfyui | bool
        - comfyui_install_check.stat.exists is defined and comfyui_install_check.stat.exists
        - comfyui_venv_check.stat.exists is defined and comfyui_venv_check.stat.exists
        - comfyui_service_status.status.ActiveState is defined and comfyui_service_status.status.ActiveState == 'active'

    - name: Test Watchtower integration
      ansible.builtin.import_tasks: ../watchtower/tasks/test.yml
      when: install_watchtower is defined and install_watchtower | bool
